{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/VectorInstitute/rag-bootcamp/blob/refactor/uv-migration/implementations/web_search/web_search_llamaindex.ipynb)\n",
    "\n",
    "# Web Search with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LlamaIndex](https://docs.llamaindex.ai/en/stable/) library to run a text-generation request on open-source LLMs and embedding models using the OpenAI SDK, then augment that request using results from Google web search.\n",
    "\n",
    "### üìù Requirements\n",
    "\n",
    "To run this notebook, you will need:\n",
    "\n",
    "\n",
    "- **OpenAI API key**:  \n",
    "    - Sign up at [OpenAI](https://platform.openai.com/) and create an API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef6ae6",
   "metadata": {},
   "source": [
    "#### Install libraries (Only in Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab024193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ:\n",
    "    # This is a Google Colab environment\n",
    "    # Install required dependencies\n",
    "    !pip3 install faiss-cpu langchain llama-index llama-index-core llama-index-embeddings-huggingface llama-index-llms-openai-like llama-index-vector-stores-faiss # aieng-rag-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a8826-fcd8-439b-8c5d-f9047fbe5c0e",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea754e1b-3f61-4562-839f-a999db8e926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import os\n",
    "\n",
    "from aieng.rag.utils import get_device_name\n",
    "from aieng.rag.utils.search import DocumentReader, pretty_print\n",
    "\n",
    "from llama_index.core import Settings, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae9862-6b55-4556-b38a-fc7ba55ee37f",
   "metadata": {},
   "source": [
    "#### Load OpenAI env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c528521-8bb4-49c6-b181-e0ecd6862e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"YOUR_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e47ff-77bc-4ecd-9e7f-8abc60fa8d81",
   "metadata": {},
   "source": [
    "#### Choose LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b28b5e-d9d9-4788-9887-5c71aedfd8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"gpt-4.1\"\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-base-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking the model a question about recent events that it doesn't know about, something that happened after it finished training. At the time I'm writing this notebook in November 2024, the model doesn't know who won the last World Series of baseball.\n",
    "\n",
    "*Who won the 2024 World Series of baseball?*\n",
    "\n",
    "**The correct answer is the Los Angeles Dodgers won in October 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who won the 2024 World Series of baseball?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bccaf41",
   "metadata": {},
   "source": [
    "## Now send the query to the open source model using KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c2663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "assistant: As of my latest update in June 2024, the 2024 World Series has not yet been played, so there is no winner to report. The World Series typically takes place in October. If you have a specific date in mind or need information about previous winners, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAILike(\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    is_chat_model=True,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    api_base=OPENAI_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "message = [ChatMessage(role=\"user\", content=query)]\n",
    "try:\n",
    "    result = llm.chat(message)\n",
    "    print(f\"Result: \\n\\n{result}\")\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {GENERATOR_MODEL_NAME} is not ready yet.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "The model admits that it doesn't know the answer, since according to the model it's a future event.\n",
    "\n",
    "Let's see how we can use RAG to augment our question with a Google web search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Do a Google web search for the query and obtain the necessary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "Parse through all the websites returned by a Google search, break them up into smaller digestible chunks, then encode them as vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 3\n",
      "Number of text chunks: 600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do a Google web search and parse the results into a big text string\n",
    "document_reader = DocumentReader(web_search_query=query, search_k=5, create_nodes=True)\n",
    "docs, chunks = document_reader.load()\n",
    "\n",
    "print(f\"Number of source documents: {len(docs)}\")\n",
    "print(f\"Number of text chunks: {len(chunks)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706de010-2ad6-4e89-a307-2ad30497fc07",
   "metadata": {},
   "source": [
    "#### Define the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f69ffb-44f0-411f-bdc3-75efe8fb0d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the embeddings model...\n"
     ]
    }
   ],
   "source": [
    "device = get_device_name()\n",
    "\n",
    "print(\"Setting up the embeddings model...\")\n",
    "embeddings = HuggingFaceEmbedding(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    device=device,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f1024-90cf-424a-9372-9dec784bc258",
   "metadata": {},
   "source": [
    "#### Set LLM and embedding model [recommended for LlamaIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7484523-4a7d-43de-9c9c-bf46425e83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ed6a7-17a1-49f3-b406-bf7c3aec4595",
   "metadata": {},
   "source": [
    "## Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a096b-85b9-45db-a9d6-dd1fde37358e",
   "metadata": {},
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. (This takes about 1-2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996df356-db4f-4e1e-90cb-9414ed0d2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_model_dim(embed_model):\n",
    "    embed_out = embed_model.get_text_embedding(\"Dummy Text\")\n",
    "    return len(embed_out)\n",
    "\n",
    "\n",
    "faiss_dim = get_embed_model_dim(embeddings)\n",
    "faiss_index = faiss.IndexFlatL2(faiss_dim)\n",
    "\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(chunks, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "891457d4-60cb-470c-b11a-3840eb85c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n",
    "retrieved_docs = retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa43e8-cf9b-42f2-bfb4-b12c00370480",
   "metadata": {},
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dffa44d-c61c-4d35-835b-eb3aa9989f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Dodgers win World Series 2024\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "The 2024 World Series was the championship series of Major League Baseball's (MLB) 2024 season. The 120th edition of the World Series, it was a best-of-seven playoff between the National League (NL) champion Los Angeles Dodgers and the American League (AL) champion New York Yankees. It was the Dodgers' first World Series appearance and win since 2020, and the Yankees' first World Series appearance since 2009. The series began on October¬†25 and ended on October¬†30 with the Dodgers winning in five\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "2024 World Series - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "Create account\n",
      "\n",
      "Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate Create account Log in\n"
     ]
    }
   ],
   "source": [
    "# Print the retrieved documents\n",
    "pretty_print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e44d26-fccb-480e-9ad2-2c48aa7dcc92",
   "metadata": {},
   "source": [
    "## Now send the query to the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab480021-1266-45c9-b4ba-45d4c22dd5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "The Los Angeles Dodgers won the 2024 World Series of baseball.\n"
     ]
    }
   ],
   "source": [
    "query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "result = query_engine.query(query)\n",
    "print(f\"Result: \\n\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d727ce-487c-447a-91b1-56616b02f557",
   "metadata": {},
   "source": [
    "The model provides the correct answer based on the information from the web."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
