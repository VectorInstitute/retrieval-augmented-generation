{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/VectorInstitute/rag-bootcamp/blob/refactor/uv-migration/implementations/web_search/web_search_langchain.ipynb)\n",
    "\n",
    "# Web Search with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LangChain](https://python.langchain.com/docs/get_started/introduction) library to run a text-generation request on open-source LLMs and embedding models using the OpenAI SDK, then augment that request using results from Google web search.\n",
    "\n",
    "### üìù Requirements\n",
    "\n",
    "To run this notebook, you will need:\n",
    "\n",
    "- **OpenAI API key**:  \n",
    "    - Sign up at [OpenAI](https://platform.openai.com/) and create an API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13265019",
   "metadata": {},
   "source": [
    "#### Install libraries (Only in Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86aa788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ:\n",
    "    # This is a Google Colab environment\n",
    "    # Install required dependencies\n",
    "    !pip3 install faiss-cpu langchain langchain-community langchain-huggingface langchain-openai # aieng-rag-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd9616-af8c-4374-9e0e-2752341c6105",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa9b3f3-9154-414e-b1bc-42bb4577ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from aieng.rag.utils import get_device_name\n",
    "from aieng.rag.utils.search import DocumentReader, pretty_print\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced0d04-2d3a-46c4-b74a-8f655f5918a3",
   "metadata": {},
   "source": [
    "#### Load OpenAI env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2d6b52-7ad1-478e-be82-36bedfa505db",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"YOUR_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff46fc-1897-4163-ae1d-15f05d1c863b",
   "metadata": {},
   "source": [
    "#### Choose LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd9e704-2c8f-41ac-b733-05b32d2caf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"gpt-4.1\"\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-base-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking the model a question about recent events that it doesn't know about, something that happened after it finished training. At the time I'm writing this notebook in November 2024, the model doesn't know who won the last World Series of baseball.\n",
    "\n",
    "*Who won the 2024 World Series of baseball?*\n",
    "\n",
    "**The correct answer is the Los Angeles Dodgers won in October 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who won the 2024 World Series of baseball?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bccaf41",
   "metadata": {},
   "source": [
    "## Now send the query to the open source model using KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c2663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "As of my latest update in June 2024, the 2024 World Series has not yet been played, so there is no winner to report. The World Series typically takes place in October. If you are seeking the most current results, please check a reliable sports news source for the latest updates.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    base_url=OPENAI_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "message = [\n",
    "    (\"human\", query),\n",
    "]\n",
    "try:\n",
    "    result = llm.invoke(message)\n",
    "    print(f\"Result: \\n\\n{result.content}\")\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {GENERATOR_MODEL_NAME} is not ready yet.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "The model admits that it doesn't know the answer, since according to the model it's a future event.\n",
    "\n",
    "Let's see how we can use RAG to augment our question with a Google web search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Do a Google web search for the query and obtain the necessary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "Parse through all the websites returned by a Google search, break them up into smaller digestible chunks, then encode them as vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 3\n",
      "Number of text chunks: 600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do a Google web search and parse the results into a big text string\n",
    "document_reader = DocumentReader(web_search_query=query, search_k=5)\n",
    "docs, chunks = document_reader.load()\n",
    "\n",
    "print(f\"Number of source documents: {len(docs)}\")\n",
    "print(f\"Number of text chunks: {len(chunks)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce30b89-b89d-493c-bc2e-f0e3663f0bf4",
   "metadata": {},
   "source": [
    "#### Define the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a0f241-a654-4ab2-8851-57a23e063e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the embeddings model...\n"
     ]
    }
   ],
   "source": [
    "device = get_device_name()\n",
    "\n",
    "model_kwargs = {\"device\": device, \"trust_remote_code\": True}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}  # set True to compute cosine similarity\n",
    "\n",
    "print(\"Setting up the embeddings model...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59402fb-b900-47bd-aa2b-401eba290c10",
   "metadata": {},
   "source": [
    "## Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bfc4e4-4c62-492d-a0b5-9de6d6985a0d",
   "metadata": {},
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. (This takes about 1-2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae20b23b-43ff-4677-a534-0f507b090d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbba2a-9212-4179-b9e3-f8feb20be299",
   "metadata": {},
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec4a394-cfe3-465f-9873-d86132bb47a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Dodgers win World Series 2024\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "2024 World Series - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "Create account\n",
      "\n",
      "Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate Create account Log in\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "2024 World Series - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "Create account\n",
      "\n",
      "Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate Create account Log in\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "The 2024 World Series was the championship series of Major League Baseball's (MLB) 2024 season. The 120th edition of the World Series, it was a best-of-seven playoff between the National League (NL) champion Los Angeles Dodgers and the American League (AL) champion New York Yankees. It was the Dodgers' first World Series appearance and win since 2020, and the Yankees' first World Series appearance since 2009. The series began on October¬†25 and ended on October¬†30 with the Dodgers winning in five\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "The 2024 World Series was the championship series of Major League Baseball's (MLB) 2024 season. The 120th edition of the World Series, it was a best-of-seven playoff between the National League (NL) champion Los Angeles Dodgers and the American League (AL) champion New York Yankees. It was the Dodgers' first World Series appearance and win since 2020, and the Yankees' first World Series appearance since 2009. The series began on October¬†25 and ended on October¬†30 with the Dodgers winning in five\n"
     ]
    }
   ],
   "source": [
    "# Print the retrieved documents\n",
    "pretty_print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2df3c5-d595-451e-aecb-117716936599",
   "metadata": {},
   "source": [
    "## Now send the query to the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b191b1-e25f-49e0-a377-e0b50023dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "The Los Angeles Dodgers won the 2024 World Series of baseball.\n"
     ]
    }
   ],
   "source": [
    "rag_pipeline = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
    "result = rag_pipeline.invoke(input=query)\n",
    "print(f\"Result: \\n\\n{result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc7d01-8605-4bcb-8078-e80d8b12dbed",
   "metadata": {},
   "source": [
    "The model provides the correct answer based on the information from the web."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-bootcamp",
   "language": "python",
   "name": "rag-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
