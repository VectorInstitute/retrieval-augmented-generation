{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/VectorInstitute/rag-bootcamp/blob/refactor/uv-migration/implementations/document_search/document_search_langchain_cohere.ipynb)\n",
    "\n",
    "# Document Search with LangChain using Cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LangChain](https://python.langchain.com/docs/get_started/introduction) library to run a text-generation request on Cohere LLMs and local embedding models, then augment that request using the text stored in a collection of local PDF documents.\n",
    "\n",
    "### üìù Requirements\n",
    "\n",
    "To run this notebook, you will need:\n",
    "\n",
    "- **Cohere API key**:  \n",
    "    - Sign up at [Cohere](https://dashboard.cohere.com/api-keys) and create an API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29114b46",
   "metadata": {},
   "source": [
    "#### Install libraries (Only in Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c564e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'COLAB_RELEASE_TAG' in os.environ:\n",
    "    # This is a Google Colab environment\n",
    "    \n",
    "    # Check if the notebook is running in a GPU environment and install the appropriate version of faiss\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        !pip3 install faiss-gpu\n",
    "    else:\n",
    "        !pip3 install faiss-cpu\n",
    "\n",
    "    # Install other dependencies\n",
    "    !pip3 install langchain langchain-community langchain-huggingface langchain-cohere # aieng-rag-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cb87e-cdf4-4002-a700-77db86d0b318",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742aa343-c90c-4e4a-8099-a3fa218e256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "\n",
    "from aieng.rag.utils import get_device_name\n",
    "from aieng.rag.utils.search import DocumentReader, pretty_print, download_file\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_cohere import ChatCohere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cfa2e4",
   "metadata": {},
   "source": [
    "#### Set Cohere API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16c8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\", \"YOUR_COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd103",
   "metadata": {},
   "source": [
    "#### Download source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c144b5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://vectorinstitute.ai/wp-content/uploads/2023/05/vector-institute-2021-22-annual-report_accessible.pdf to source_documents/vector-institute-2021-22-annual-report_accessible.pdf\n"
     ]
    }
   ],
   "source": [
    "DIRECTORY_PATH = \"./source_documents\"\n",
    "DOCUMENT_URL = \"https://vectorinstitute.ai/wp-content/uploads/2023/05/vector-institute-2021-22-annual-report_accessible.pdf\"\n",
    "\n",
    "download_file(DOCUMENT_URL, DIRECTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c93ad-fe81-4acd-9ea3-eca9b425ee9a",
   "metadata": {},
   "source": [
    "#### Choose Cohere LLM and local embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2553d130-5b02-4852-928f-beb7ecd05d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"command-r\"\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-base-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking Cohere a difficult, domain-specific question we don't expect it to have an answer to. A simple question like \"*What is the capital of France?*\" is not a good question here, because that's world knowledge that we expect the LLM to know.\n",
    "\n",
    "Instead, we want to ask it a question that is domain-specific and it won't know the answer to. A good example would be an obscure detail buried deep within a company's annual report. For example:\n",
    "\n",
    "*How many Vector scholarships in AI were awarded in 2022?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many Vector scholarships in AI were awarded in 2022?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a22c5",
   "metadata": {},
   "source": [
    "## Now send the query to the open source model using KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00061d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "According to the official Vector Institute website, in 2022, a total of 42 scholarships were awarded to outstanding students across Canada as part of the Vector Institute's Graduate Scholarship Program. These scholarships are aimed at supporting exceptional master's and doctoral students conducting research in the field of artificial intelligence (AI) and related areas. \n",
      "\n",
      "The Vector Institute, based in Toronto, Ontario, is a hub for AI research and innovation, focusing on building Canada's capacity in AI. The institute offers these scholarships to attract top talent and foster excellence in AI research. \n",
      "\n",
      "The 42 scholarship recipients in 2022 were selected based on their potential to become top researchers and leaders in AI. They each received $10,000 in funding to support their studies. These scholarships are a step towards fostering a vibrant AI ecosystem and building a talented workforce in Canada. \n",
      "\n",
      "The number of scholarships awarded can vary each year, so it's recommended to check the latest information on the Vector Institute's website or reach out to them directly for the most up-to-date details on their scholarship programs.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatCohere(\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    temperature=0,\n",
    "    max_tokens=128,\n",
    "    cohere_api_key=COHERE_API_KEY,\n",
    ")\n",
    "message = [\n",
    "    (\"human\", query),\n",
    "]\n",
    "\n",
    "result = llm.invoke(message)\n",
    "print(f\"Result: \\n\\n{result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "Without additional information, Cohere is unable to answer the question correctly. **Vector in fact awarded 109 AI scholarships in 2022.** Fortunately, we do have that information available in Vector's 2021-22 Annual Report, which is available in the `source_documents` folder. Let's see how we can use RAG to augment our question with a document search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Load and store the documents from `source_documents`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "Start by reading in all the PDF files from `source_documents`, break them up into smaller digestible chunks, then encode them as vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 42\n",
      "Number of text chunks: 196\n"
     ]
    }
   ],
   "source": [
    "# Load PDFs\n",
    "doc_reader = DocumentReader(directory_path=DIRECTORY_PATH)\n",
    "docs, chunks = doc_reader.load()\n",
    "\n",
    "print(f\"Number of source documents: {len(docs)}\")\n",
    "print(f\"Number of text chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3fd15-213f-4774-88e0-bbdadf28789c",
   "metadata": {},
   "source": [
    "#### Define the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b42902-d145-4f61-80c2-334a4b1da886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the embeddings model...\n"
     ]
    }
   ],
   "source": [
    "device = get_device_name()\n",
    "\n",
    "model_kwargs = {'device': device, 'trust_remote_code': True}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "print(f\"Setting up the embeddings model...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7545e",
   "metadata": {},
   "source": [
    "## Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc16fe",
   "metadata": {},
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. (This takes about 1-2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1048c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1690e",
   "metadata": {},
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51dc81d7-8333-41e6-9e77-47a45ee0b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "5 \n",
      "Annual Report 2021‚Äì22Vector Institute\n",
      "SPOTLIGHT ON FIVE YEARS OF AI \n",
      "LEADERSHIP FOR CANADIANS \n",
      "SINCE THE VECTOR INSTITUTE WAS FOUNDED IN 2017: \n",
      "2,080+ \n",
      "Students have graduated from \n",
      "Vector-recognized AI programs and \n",
      "study paths \n",
      "$6.2 M \n",
      "Scholarship funds committed to \n",
      "students in AI programs \n",
      "3,700+ \n",
      "Postings for AI-focused jobs and \n",
      "internships ofered on Vector‚Äôs \n",
      "Digital Talent Hub \n",
      "$103 M \n",
      "In research funding committed to \n",
      "Vector-afliated researchers \n",
      "94 \n",
      "Research awards earned by\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "26 \n",
      " \n",
      " \n",
      "VECTOR SCHOLARSHIPS IN \n",
      "AI ATTRACT TOP TALENT \n",
      "TO ONTARIO UNIVERSITIES \n",
      "109 \n",
      "Vector Scholarships in AI awarded \n",
      "34 \n",
      "Programs \n",
      "13 \n",
      "Universities \n",
      "351 \n",
      "Scholarships awarded since the \n",
      "program launched in 2018 \n",
      "Supported with funding from the Province of \n",
      "Ontario, the Vector Institute Scholarship in Artifcial \n",
      "Intelligence (VSAI) helps Ontario universities to attract \n",
      "the best and brightest students to study in AI-related \n",
      "master‚Äôs programs. \n",
      "Scholarship recipients connect directly with leading\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "The complete Ontario AI Snapshot for 2021‚Äì22 will be available soon on the \n",
      "Vector Institute website at vectorinstitute.ai. \n",
      "YoY \n",
      "22,458 \n",
      "AI jobs created \n",
      "YoY \n",
      "59,67 3 \n",
      "AI jobs retained \n",
      "YoY \n",
      "1,775 \n",
      "New AI Master‚Äôs & study \n",
      "path enrolments \n",
      "YoY \n",
      "1,007 \n",
      "New AI Master‚Äôs graduates from \n",
      "Vector-recognized programs \n",
      "YoY \n",
      "66 \n",
      "New AI-related patents \n",
      "fled across Canada \n",
      "YoY \n",
      "$2.86 BILLION \n",
      "In AI-related VC investment* \n",
      "YoY \n",
      "273 \n",
      "Companies invested in \n",
      "the Ontario AI ecosystem \n",
      "YoY \n",
      "50 \n",
      "Companies moved into\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "23 \n",
      "RESEARCH AWARDS AND \n",
      "ACHIEVEMENTS \n",
      "Each year, members of Vector‚Äôs research community \n",
      "are recognized for outstanding contributions to AI and \n",
      "machine learning felds. Highlights of 2021‚Äì22 include: \n",
      "GLOBAL REACH OF VECTOR \n",
      "RESEARCHERS AND THEIR WORK \n",
      "Vector researchers published papers, gave \n",
      "presentations, or led workshops at many of the \n",
      "top AI conferences this year, including NeurIPS, \n",
      "CVPR, ICLR, ICML, and ACM FAccT. \n",
      "380+ Research papers presented at  \n",
      "high-impact global \n",
      "conferences and in top-\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "16 V ector Institute Annual Report 2021‚Äì22 \n",
      "RESEARCH & \n",
      "EDUCATION \n",
      "Vector is advancing the frontiers of \n",
      "AI knowledge \n",
      "What was once only a few founding faculty has evolved \n",
      "over the last fve years into a fourishing community \n",
      "comprising over 700 researchers who are pushing the \n",
      "boundaries of AI, machine learning, and deep learning \n",
      "in critical areas to beneft Ontarians, Canadians, and \n",
      "people around the world. \n",
      "Vector continues to drive this growth through new and\n"
     ]
    }
   ],
   "source": [
    "pretty_print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5e95e-f127-4092-b960-33b39ad21147",
   "metadata": {},
   "source": [
    "## Now send the query to the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26d9f46-a082-4497-8ffc-9fa3eccc2ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "I'm unable to provide a definitive answer as the year the scholarships were awarded is not stated within the text provided. However, it does mention that 351 scholarships have been awarded since the program's launch in 2018.\n",
      "\n",
      "In the section highlighting the 2021-22 annual report, it states that Vector Institute has helped facilitate 2,080+ student graduations from AI programs and study paths, and that $6.2M in scholarship funds have been committed to students in AI programs. It's unclear if the funds mentioned are solely related to the Vector Scholarships in AI or includes additional scholarship programs.\n"
     ]
    }
   ],
   "source": [
    "rag_pipeline = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
    "result = rag_pipeline.invoke(input=query)\n",
    "print(f\"Result: \\n\\n{result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008507b",
   "metadata": {},
   "source": [
    "The model provides the correct answer (109) using the retrieved information, but is somewhat confused with the year."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
